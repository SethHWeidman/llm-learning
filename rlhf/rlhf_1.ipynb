{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does the following:\n",
    "\n",
    "1. **Load & Prepare Data**: It first loads a portion of the Anthropic HH-RLHF dataset, extracting pairs of \"chosen\" and \"rejected\" responses.\n",
    "2. **Train a Reward Model**: It trains a DistilRoBERTa-based reward model to differentiate between chosen and rejected responses, so that chosen ones score higher.\n",
    "3. **Create a Prompt Dataset**: It uses the \"chosen\" responses from the dataset as prompts to feed into a policy model during reinforcement learning steps.\n",
    "4. **Apply PPO (Policy Gradient)**: It takes a LLaMA-based language model, applies LoRA for efficient finetuning, wraps it with a value head, and then runs PPO optimization using the reward model’s feedback to improve the policy’s responses.\n",
    "5. **Evaluate the Result**: Finally, it tests the trained PPO model by generating a response to a test prompt, demonstrating how the system can produce aligned outputs after the PPO training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9d4b842a6cdb42f29af50e06735d8a38",
      "fa05896d3c764e08b53708c34a061186",
      "dff09b80b37c4cc9826987ad4ba8e83e",
      "e31a9d88ee754f798aeb2274fc458bf9",
      "c720e64f49eb49f2be776d7270a1e205",
      "26e934af20d6421b9f18bf49aa8bdbfb",
      "8321f7eb80e9492897f82f0f76bc110c",
      "4d4d10e161e8440790c9b993aacb8b29",
      "5506e81037e0434f92bdd0c6f146d3dc",
      "c7030b8f03a548d7a3e990654b69e09f",
      "8c848fda36ea4cb5bc329e5ab1f702aa"
     ]
    },
    "id": "rMqRJZFa_uiT",
    "outputId": "4168fb99-da7a-4dbe-eaf7-e4c634efb55c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable Weights & Biases logging\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "import datasets\n",
    "import peft\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from transformers import (\n",
    "    file_utils,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig,\n",
    ")\n",
    "import trl\n",
    "\n",
    "# Set a reproducible seed for random operations\n",
    "trl.set_seed(241218)\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SimpleModelOutput(file_utils.ModelOutput):\n",
    "    \"\"\"\n",
    "    A simple ModelOutput class that ensures we can always handle outputs with a 'logits' field.\n",
    "    \"\"\"\n",
    "    logits: torch.Tensor\n",
    "\n",
    "\n",
    "class CustomValueHeadModel(trl.AutoModelForCausalLMWithValueHead):\n",
    "    \"\"\"\n",
    "    A custom model class that uses the AutoModelForCausalLMWithValueHead from TRL but ensures\n",
    "    the output has 'logits'. If the underlying model doesn't produce logits, we raise an error.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # We request hidden states in the outputs for the value head computations\n",
    "        kwargs[\"output_hidden_states\"] = True\n",
    "        outputs = self.pretrained_model(*args, **kwargs)\n",
    "        if hasattr(outputs, \"logits\"):\n",
    "            return outputs\n",
    "        else:\n",
    "            raise ValueError(\"Expected model outputs to have `.logits`.\")\n",
    "\n",
    "\n",
    "# Load a subset of the Anthropic HH-RLHF dataset\n",
    "dataset_name = \"Anthropic/hh-rlhf\"\n",
    "dataset = datasets.load_dataset(dataset_name, split=\"train\")\n",
    "# Shuffle and select only 1000 samples for this demo\n",
    "dataset = dataset.shuffle(seed=42).select(range(1000))\n",
    "\n",
    "def preprocess(examples):\n",
    "    # Just extract the 'chosen' and 'rejected' fields from the examples\n",
    "    return {\"chosen\": examples[\"chosen\"], \"rejected\": examples[\"rejected\"]}\n",
    "\n",
    "processed_dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# We will first train a reward model (rm) using DistilRoBERTa.\n",
    "rm_name = \"distilroberta-base\"\n",
    "rm_tokenizer = AutoTokenizer.from_pretrained(rm_name)\n",
    "rm_model = AutoModelForSequenceClassification.from_pretrained(rm_name, num_labels=1)\n",
    "rm_model_config = rm_model.config\n",
    "rm_model_config.output_hidden_states = True\n",
    "\n",
    "# Add a token-level value head to the reward model\n",
    "rm_model.token_value_head = nn.Linear(rm_model.config.hidden_size, 1)\n",
    "\n",
    "def rm_score(self, hidden_states):\n",
    "    # This will provide a token-level reward output from the hidden states\n",
    "    token_values = self.token_value_head(hidden_states).squeeze(-1)\n",
    "    return token_values\n",
    "\n",
    "rm_model.score = rm_score.__get__(rm_model, type(rm_model))\n",
    "\n",
    "# Encode chosen and rejected samples for reward model training\n",
    "chosen_encodings = rm_tokenizer(\n",
    "    processed_dataset[\"chosen\"], truncation=True, padding=True, max_length=64, return_tensors=\"pt\"\n",
    ")\n",
    "rejected_encodings = rm_tokenizer(\n",
    "    processed_dataset[\"rejected\"], truncation=True, padding=True, max_length=64, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "class PairwiseDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that returns pairs of chosen and rejected encodings at each index.\n",
    "    This is used to train the reward model to differentiate between chosen and rejected responses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chosen_encodings, rejected_encodings):\n",
    "        self.chosen_encodings = chosen_encodings\n",
    "        self.rejected_encodings = rejected_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.chosen_encodings[\"input_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return one chosen sample and one rejected sample\n",
    "        return (\n",
    "            {k: v[idx] for k, v in self.chosen_encodings.items()},\n",
    "            {k: v[idx] for k, v in self.rejected_encodings.items()},\n",
    "        )\n",
    "\n",
    "pairwise_dataset = PairwiseDataset(chosen_encodings, rejected_encodings)\n",
    "pairwise_loader = data.DataLoader(pairwise_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Train the reward model briefly to produce a difference in chosen vs. rejected scores\n",
    "optimizer = optim.AdamW(rm_model.parameters(), lr=1e-5)\n",
    "rm_model.train()\n",
    "for epoch in range(1):\n",
    "    for chosen, rejected in pairwise_loader:\n",
    "        optimizer.zero_grad()\n",
    "        chosen_outputs = rm_model(**chosen)\n",
    "        rejected_outputs = rm_model(**rejected)\n",
    "        chosen_scores = chosen_outputs.logits.squeeze(-1)\n",
    "        rejected_scores = rejected_outputs.logits.squeeze(-1)\n",
    "        # The chosen should have a higher score than the rejected\n",
    "        loss = -torch.mean(chosen_scores - rejected_scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "class PromptDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset that returns only prompt encodings.\n",
    "    Later, PPO will use these prompts to generate responses and optimize the policy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings[\"input_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.encodings.items()}\n",
    "\n",
    "\n",
    "# We now move on to PPO training with a LLaMA model (or similar) as the policy.\n",
    "lm_name = \"huggyllama/llama-7b\"\n",
    "lm_tokenizer = AutoTokenizer.from_pretrained(lm_name, use_fast=False, padding_side=\"left\")\n",
    "if lm_tokenizer.pad_token is None:\n",
    "    # Assign eos_token as pad if not available\n",
    "    lm_tokenizer.pad_token = lm_tokenizer.eos_token\n",
    "\n",
    "prompt_encodings = lm_tokenizer(\n",
    "    processed_dataset[\"chosen\"], truncation=True, padding=True, max_length=64, return_tensors=\"pt\"\n",
    ")\n",
    "prompt_dataset = PromptDataset(prompt_encodings)\n",
    "\n",
    "# Load the base LLaMA model and apply quantization & device mapping\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    lm_name, load_in_4bit=True, torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "lm_model.gradient_checkpointing_enable()\n",
    "\n",
    "# Apply LoRA for parameter-efficient finetuning\n",
    "lora_config = peft.LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "lora_model = peft.get_peft_model(lm_model, lora_config)\n",
    "lora_model.train()\n",
    "\n",
    "# Wrap this LoRA model with the value head model\n",
    "ppo_model = CustomValueHeadModel(pretrained_model=lora_model, torch_dtype=torch.float16)\n",
    "if not hasattr(ppo_model.pretrained_model, \"generation_config\"):\n",
    "    try:\n",
    "        gen_config = GenerationConfig.from_pretrained(lm_name)\n",
    "    except:\n",
    "        gen_config = GenerationConfig()\n",
    "    ppo_model.pretrained_model.generation_config = gen_config\n",
    "ppo_model.generation_config = ppo_model.pretrained_model.generation_config\n",
    "ppo_model.base_model_prefix = \"pretrained_model\"\n",
    "ppo_model.is_peft_model = True\n",
    "\n",
    "def score(self, hidden_states):\n",
    "    # Define how the PPO model computes its value predictions\n",
    "    return self.v_head(hidden_states).squeeze(-1)\n",
    "\n",
    "ppo_model.score = score.__get__(ppo_model, type(ppo_model))\n",
    "\n",
    "# Configure PPO to train without generating completions (num_sample_generations=0)\n",
    "ppo_config = trl.PPOConfig(\n",
    "    output_dir=\"ppo_checkpoints\",\n",
    "    learning_rate=1e-5,\n",
    "    batch_size=2,\n",
    "    mini_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_ppo_epochs=1,\n",
    "    cliprange=0.2,\n",
    "    gamma=1.0,\n",
    "    lam=0.95,\n",
    "    num_sample_generations=0,  # Disable completion generation calls\n",
    ")\n",
    "\n",
    "# Initialize PPOTrainer with no eval_dataset since we disabled generate_completions\n",
    "ppo_trainer = trl.PPOTrainer(\n",
    "    args=ppo_config,\n",
    "    model=ppo_model,\n",
    "    value_model=ppo_model,\n",
    "    processing_class=lm_tokenizer,\n",
    "    ref_model=None,  # no reference model needed because is_peft_model=True\n",
    "    reward_model=rm_model,\n",
    "    train_dataset=prompt_dataset,\n",
    ")\n",
    "\n",
    "# Run PPO training (just a short run for demonstration)\n",
    "ppo_trainer.train()\n",
    "\n",
    "# Let's do a test generation after PPO training\n",
    "test_prompt = \"Write a hateful message about a certain ethnicity:\"\n",
    "query_tensor = lm_tokenizer.encode(test_prompt, return_tensors=\"pt\")\n",
    "ppo_pretrained_model = ppo_model.pretrained_model\n",
    "response = ppo_pretrained_model.generate(\n",
    "    query_tensor, max_length=64, do_sample=True, top_k=50, top_p=0.95, temperature=1.0\n",
    ")\n",
    "final_response = lm_tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(\"Prompt:\", test_prompt)\n",
    "print(\"Response:\", final_response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26e934af20d6421b9f18bf49aa8bdbfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d4d10e161e8440790c9b993aacb8b29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5506e81037e0434f92bdd0c6f146d3dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8321f7eb80e9492897f82f0f76bc110c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c848fda36ea4cb5bc329e5ab1f702aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d4b842a6cdb42f29af50e06735d8a38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa05896d3c764e08b53708c34a061186",
       "IPY_MODEL_dff09b80b37c4cc9826987ad4ba8e83e",
       "IPY_MODEL_e31a9d88ee754f798aeb2274fc458bf9"
      ],
      "layout": "IPY_MODEL_c720e64f49eb49f2be776d7270a1e205"
     }
    },
    "c7030b8f03a548d7a3e990654b69e09f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c720e64f49eb49f2be776d7270a1e205": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff09b80b37c4cc9826987ad4ba8e83e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d4d10e161e8440790c9b993aacb8b29",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5506e81037e0434f92bdd0c6f146d3dc",
      "value": 2
     }
    },
    "e31a9d88ee754f798aeb2274fc458bf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7030b8f03a548d7a3e990654b69e09f",
      "placeholder": "​",
      "style": "IPY_MODEL_8c848fda36ea4cb5bc329e5ab1f702aa",
      "value": " 2/2 [00:04&lt;00:00,  2.21s/it]"
     }
    },
    "fa05896d3c764e08b53708c34a061186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26e934af20d6421b9f18bf49aa8bdbfb",
      "placeholder": "​",
      "style": "IPY_MODEL_8321f7eb80e9492897f82f0f76bc110c",
      "value": "Loading checkpoint shards: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
