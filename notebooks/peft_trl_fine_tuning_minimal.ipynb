{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxBKz4qY9tHa"
      },
      "source": [
        "* https://huggingface.co/docs/bitsandbytes/v0.43.2/index\n",
        "* https://huggingface.co/docs/peft/en/index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU bitsandbytes datasets peft trl"
      ],
      "metadata": {
        "id": "wncZUV88cfXu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B8bwhzLktzx",
        "outputId": "8af6c71a-a772-4d76-a7e9-f8698195cc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    'ignore',\n",
        "    message='The secret `HF_TOKEN` does not exist'\n",
        "  )\n",
        "\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "import huggingface_hub\n",
        "import peft\n",
        "import torch\n",
        "from torch import cuda as torch_cuda\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import trl\n",
        "\n",
        "!pwd\n",
        "import sys\n",
        "sys.path.append(\"../llm-learning\")\n",
        "\n",
        "from utils import jupyter_formatting\n",
        "\n",
        "jupyter_formatting.setup_notebook_formatting()\n",
        "\n",
        "torch_cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cA2VMaWjlKg0"
      },
      "outputs": [],
      "source": [
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bonwp1mQZFoR"
      },
      "source": [
        "* https://huggingface.co/NousResearch/Meta-Llama-3.1-8B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9yU8vbs8jpX",
        "outputId": "8bc4c7a1-2990-41b9-f4e5-1d11f00165f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MODEL_ID = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wdOOdMjIRxII"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    first_gpu = torch_cuda.get_device_properties(0)\n",
        "\n",
        "    print(\n",
        "        \"\"\"\\\n",
        "        Memory allocated: {0:.2f} MB \\\n",
        "        Memory reserved: {1:.2f} MB\\\n",
        "\n",
        "        Total GPUs: {2}\n",
        "        GPU's memory: {3:.1f} MB\n",
        "        \"\"\".format(\n",
        "                  torch_cuda.memory_allocated() / 1_024**2,\n",
        "                  torch_cuda.memory_reserved() / 1_024**2,\n",
        "                  torch_cuda.device_count(),\n",
        "                  first_gpu.total_memory / 1_024**2,\n",
        "              )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lZ5IYoVuU9om"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # Replace the model id with your specific model\n",
        "    MODEL_ID = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "    # Download config.json file from the Hugging Face hub\n",
        "    config_file_path = huggingface_hub.hf_hub_download(MODEL_ID, \"config.json\")\n",
        "    print(config_file_path)\n",
        "\n",
        "    index_file_path = huggingface_hub.hf_hub_download(\n",
        "        MODEL_ID, \"model.safetensors.index.json\"\n",
        "    )\n",
        "    print(index_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fo5y3m7mUDJr"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    import json\n",
        "\n",
        "    with open(config_file_path, \"r\") as config_file:\n",
        "        config_data = json.load(config_file)\n",
        "        print(json.dumps(config_data, indent=4))\n",
        "\n",
        "    with open(index_file_path, \"r\") as index_file:\n",
        "        index_data = json.load(index_file)\n",
        "        print(json.dumps(index_data, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rsPMHAtnWcr1"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA2Qcp-KCtZI",
        "outputId": "c8cd2b8a-f9ad-42d8-eaf6-8fc2eb250bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSN7Ht0jCbuu",
        "outputId": "d2c6abe2-e566-4f81-94ef-f71bbd1aacc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'legal_summarization'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 31 (delta 2), reused 0 (delta 0), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (31/31), 136.60 KiB | 22.77 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lauramanor/legal_summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gbQ7EdZqXeZ-"
      },
      "outputs": [],
      "source": [
        "jsonl_array = []\n",
        "with open(\"legal_summarization/tldrlegal_v1.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for _, value in data.items():\n",
        "        jsonl_array.append(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_8VaDsbXq4k",
        "outputId": "3ada0de1-6759-4a9e-b766-37a816f1205a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['doc', 'id', 'original_text', 'reference_summary', 'title', 'uid'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "jsonl_array[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTNTODwGZFoT"
      },
      "source": [
        "* https://huggingface.co/docs/datasets/en/index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "no6MqHcrXwvk"
      },
      "outputs": [],
      "source": [
        "legal_dataset = Dataset.from_list(jsonl_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjK2stUKLdwK",
        "outputId": "e4f0848b-4153-4b1a-8422-fe1f4280b3cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['doc', 'id', 'original_text', 'reference_summary', 'title', 'uid'],\n",
              "    num_rows: 85\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "legal_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cUfi5dMZt1k5"
      },
      "outputs": [],
      "source": [
        "legal_dataset = legal_dataset.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E5uVoOA0t6PJ"
      },
      "outputs": [],
      "source": [
        "legal_dataset_test_valid = legal_dataset[\"test\"].train_test_split(test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_JnSF82CY5ws"
      },
      "outputs": [],
      "source": [
        "legal_dataset = datasets.DatasetDict(\n",
        "    {\n",
        "        \"train\": legal_dataset[\"train\"],\n",
        "        \"test\": legal_dataset_test_valid[\"test\"],\n",
        "        \"validation\": legal_dataset_test_valid[\"train\"],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg5n3M-nZIJu",
        "outputId": "0d1d495f-b657-4b95-c69c-d133b065955d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['doc', 'id', 'original_text', 'reference_summary', 'title', 'uid'],\n",
              "        num_rows: 68\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['doc', 'id', 'original_text', 'reference_summary', 'title', 'uid'],\n",
              "        num_rows: 9\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['doc', 'id', 'original_text', 'reference_summary', 'title', 'uid'],\n",
              "        num_rows: 8\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "legal_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scuhjiffMWi5",
        "outputId": "3bd3f0e4-247b-48dc-81e5-99ef90e113ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "    \"doc\": \"Android SDK License Agreement (June 2014)\",\n",
              "    \"id\": \"543ed49a98d9d5a17e000268\",\n",
              "    \"original_text\": \"you agree to use the sdk and write applications only for purposes that are\n",
              "    permitted by a the license agreement and b any applicable law regulation or generally accepted\n",
              "    practices or guidelines in the relevant jurisdictions including any laws regarding the export\n",
              "    of data or software to and from the united states or other relevant countries.\",\n",
              "    \"reference_summary\": \"stay within the law and license agreement.\",\n",
              "    \"title\": \"4.2\",\n",
              "    \"uid\": \"legalsum51\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "legal_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cz9b2HSEzU"
      },
      "source": [
        "### Instruction Templating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL5hOe-tQATQ"
      },
      "source": [
        "https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4-61OlX5QEUk"
      },
      "outputs": [],
      "source": [
        "INSTRUCTION_PROMPT_TEMPLATE = \"\"\"\\\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "Please convert the following legal content into a short human-readable summary<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "[LEGAL_DOC]{LEGAL_TEXT}[END_LEGAL_DOC]<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "RESPONSE_TEMPLATE = \"\"\"\\\n",
        "{NATURAL_LANGUAGE_SUMMARY}<|eot_id|><|end_of_text|>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p4z98mSPm0LZ"
      },
      "outputs": [],
      "source": [
        "def create_prompt(sample: str, include_response: bool = True) -> str:\n",
        "    full_prompt = INSTRUCTION_PROMPT_TEMPLATE.format(LEGAL_TEXT=sample[\"original_text\"])\n",
        "\n",
        "    if include_response:\n",
        "        full_prompt += RESPONSE_TEMPLATE.format(\n",
        "            NATURAL_LANGUAGE_SUMMARY=sample[\"reference_summary\"]\n",
        "        )\n",
        "\n",
        "    return full_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzI2Q3POEvJe",
        "outputId": "0e0bb04f-83c4-4a5d-9785-3431928995f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Please convert the following legal content into a short human-readable summary<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "[LEGAL_DOC]the app permits the purchase of virtual currency virtual money and use of that virtual money to purchase virtual items or services that we expressly make available for use in the app virtual goods. the purchase of virtual money and virtual goods is limited to account holders who are either a 18 years of age or older or b under the age of 18 and have the consent of a parent to make the purchase. parents of children under the age of 18 can consult the ios or google play settings for their app to restrict in app purchases but should also monitor their children s accounts for unexpected activity including the purchase of virtual money or virtual goods. purchases of virtual money and virtual goodsvirtual money is a category of content so the purchase of virtual money grants you only a limited nontransferable non sublicensable revocable license to use such virtual money to access and purchase virtual goods in conjunction with your personal noncommercial use of the services. you acknowledge that you do not acquire any ownership rights in or to the virtual money virtual goods or other content any balance of virtual goods or virtual money does not reflect any stored value. you agree that virtual money and virtual goods have no monetary value and do not constitute actual currency or property of any type. virtual money may be redeemed only for virtual goods and can never be sold transferred or exchanged for real money real goods or real services from us or anyone else. you also agree that you will only obtain virtual money and or virtual goods from us and through means provided by us and not from any third party platform exchange broker or other mechanism unless expressly authorized. once you acquire a license to virtual money or virtual goods you may not trade or transfer the virtual money or virtual goods to another individual or account unless such functionality is provided to you by us by way of a feature or service whether inside the app or through some other method e g our website. we may cancel any virtual money or virtual goods sold transferred or exchanged in violation of these terms. any such sale transfer or exchange or attempt to do so is prohibited and may result in the termination of your account. during the term of your license to your virtual money you have the right to redeem your virtual money for selected virtual goods. if you are the parent and you are accepting these terms on behalf of your child you accept and acknowledge that your child has your consent to exercise this right independently. pricing and availability of virtual money and virtual goods are subject to change without notice. we reserve the right at any time to change and update our pricing and inventory of virtual money and virtual goods. as set forth below all virtual money virtual goods and other content is provided as is without any warranty. you agree that all sales by us to you of virtual money and virtual goods are final and that we will not permit exchanges or refunds for any unused virtual money or virtual goods once the transaction has been made. purchases by end users outside the u s virtual money and virtual goods may only be purchased and held by legal residents of countries where access to and use of the services are permitted. if you live in the european union you have certain rights to withdraw from online purchases. however please note that once you download virtual money from us your right of withdrawal ends. you agree that a purchase of virtual money involves immediate download of such content and b you lose your right of withdrawal once your purchase is complete. if you live in the european union we will provide you with a vat invoice when we are required to do so by law. you agree that these invoices may be electronic in format. we reserve the right to control regulate change or remove any virtual money or virtual goods without any liability to you.[END_LEGAL_DOC]<|eot_id|><|start_header_id|>assistant<|end_header_id|>you can spend money on coins pokeballs. we ain t giving you that money back. want to buy gold online. too bad. oh and the eu gives people refund rights in some cases. not this one.<|eot_id|><|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "print(create_prompt(legal_dataset[\"test\"][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mERZFXCdFLgI"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      - prompt: str representing formatted prompt\n",
        "      - model: model object\n",
        "      - tokenizer: tokenizer object\n",
        "\n",
        "    Functionality:\n",
        "      This will allow our model to generate a response to a prompt!\n",
        "\n",
        "    Returns:\n",
        "      - str response of the model\n",
        "    \"\"\"\n",
        "\n",
        "    # convert str input into tokenized input\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # send the tokenized inputs to our GPU\n",
        "    model_inputs = encoded_input.to(\"cuda\")\n",
        "\n",
        "    # generate response and set desired generation parameters\n",
        "    generated_ids = model.generate(\n",
        "        **model_inputs,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # decode output from tokenized output to str output\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "    # return only the generated response (not the prompt) as output\n",
        "    return decoded_output[0].split(\"<|end_header_id|>\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IQLq-a5XnMZg"
      },
      "outputs": [],
      "source": [
        "def generate_response(\n",
        "    prompt: str,\n",
        "    model: transformers.AutoModelForCausalLM,\n",
        "    tokenizer: transformers.AutoTokenizer,\n",
        ") -> str:\n",
        "    # convert str input into tokenized input\n",
        "    encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # send the tokenized inputs to our GPU\n",
        "    model_inputs = encoded_input.to(\"cuda\")\n",
        "\n",
        "    # generate response and set desired generation parameters\n",
        "    generated_ids = model.generate(\n",
        "        **model_inputs,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # decode output from tokenized output to str output\n",
        "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "    # return only the generated response (not the prompt) as output\n",
        "    return decoded_output[0].split(\"<|end_header_id|>\")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2JUb6X9UFPbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "7400a157-8e14-4c01-d108-bf6d6eebdca3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nHere's a short human-readable summary:\\n\\n**Virtual Currency and Goods Terms**\\n\\nWhen you buy virtual currency and goods in our app, you're only getting a license to use them, not ownership. You can't sell, transfer, or exchange them for real money or goods. You can only obtain virtual currency and goods from us through our app or website, not from third-party platforms.\\n\\n**Key Points:**\\n\\n* You must be 18 or older, or have parental consent, to buy virtual currency and goods.\\n* Virtual currency and goods have no monetary value and can't be sold or exchanged for real money or goods.\\n* You can't trade or transfer virtual currency and goods to others unless we provide a feature to do so.\\n* We can cancel any virtual currency or goods sold or transferred in violation of these terms.\\n* Prices and availability of virtual currency and goods can change without notice.\\n* All sales are final, and we won't permit exchanges or refunds.\\n* If you're a parent, you're responsible for monitoring your child's account and restricting in-app purchases.\\n\\n**Additional EU-specific terms:**\\n\\n* If you're a EU resident, you have the right to withdraw from online purchases, but this right ends once you download virtual currency.\\n* We'll provide\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generate_response(\n",
        "    create_prompt(legal_dataset[\"test\"][1], include_response=False), model, tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RezcTeu7Ql1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "62ba0ccd-4a14-4559-b307-397a58d0ed9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you can spend money on coins pokeballs. we ain t giving you that money back. want to buy gold online. too bad. oh and the eu gives people refund rights in some cases. not this one.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Ground Truth Summary\n",
        "legal_dataset[\"test\"][1][\"reference_summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "894V7SAaevsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "9f958464-a6fd-4ca9-b58c-4382ebbc5f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nHere's a short, human-readable summary:\\n\\n**Creating a YouTube Account**\\n\\nTo access some YouTube features, you'll need to create a YouTube or Google account. You're responsible for:\\n\\n* Providing accurate and complete information when creating your account\\n* Keeping your account password secure\\n* Notifying YouTube immediately if you suspect unauthorized use of your account\\n\\nIf someone uses your account without permission, you may be liable for any losses, but YouTube is not responsible for unauthorized use.<|eot_id|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Let's try another just to see how the model responds to a different prompt.\n",
        "generate_response(\n",
        "    create_prompt(legal_dataset[\"test\"][3], include_response=False), model, tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TDr329g8eyr_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b2dc7cd-cd3c-4de6-ca82-a285f4e25802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'don t lie when you create your account. tell us immediately when your account has been compromised.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Ground Truth Summary\n",
        "legal_dataset[\"test\"][3][\"reference_summary\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXNW9sbI_1u_"
      },
      "source": [
        "### Required Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "klHIwFqgG85s"
      },
      "outputs": [],
      "source": [
        "model_config = model.config\n",
        "model = peft.prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qk0mSs_7E2"
      },
      "source": [
        "## Task #3: Setting up PEFT LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5cVJcDWYKG0h"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model: transformers.AutoModelForCausalLM) -> None:\n",
        "\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    print(\n",
        "        \"trainable params: {0} || all params: {1} || trainable%: {2}\".format(\n",
        "            trainable_params, all_param, 100 * trainable_params / all_param\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N11Mu9RAEVO"
      },
      "source": [
        "#### Initializing LoRA Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCJ9XrmsJJTZ"
      },
      "source": [
        "https://huggingface.co/docs/peft/main/en/package_reference/lora#peft.LoraConfig\n",
        "https://huggingface.co/docs/peft/main/en/package_reference/peft_model#peft.get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9pr7p_mPHmML"
      },
      "outputs": [],
      "source": [
        "# set our rank (higher value is more memory/better performance)\n",
        "lora_r = 16\n",
        "\n",
        "# set our dropout (default value)\n",
        "lora_dropout = 0.1\n",
        "\n",
        "# rule of thumb: alpha should be (lora_r * 2)\n",
        "lora_alpha = 32\n",
        "\n",
        "# construct our LoraConfig with the above hyperparameters\n",
        "peft_config = peft.LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = peft.get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-BrOR1FBcbG",
        "outputId": "6a898ead-d464-456f-e493-fd9c4e83dedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 41943040 || all params: 4582543360 || trainable%: 0.9152786281546499\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwm5wUpN9TJm",
        "outputId": "0594681a-7f0f-4486-f301-311519b3992c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): Embedding(128256, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaSdpaAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (rotary_emb): LlamaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        (rotary_emb): LlamaRotaryEmbedding()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrBzhBTGHGLy"
      },
      "source": [
        "## Task #4: Training the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWtLUFNY7XDC"
      },
      "source": [
        "### Setting up Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P0aN7bYf_bLj"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 2_048\n",
        "\n",
        "args = trl.SFTConfig(\n",
        "    output_dir=\"llama381binstruct_summarize_short\",\n",
        "    max_steps=500,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=30,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,\n",
        "        \"append_concat_token\": False,\n",
        "    },\n",
        "    max_seq_length=max_seq_length,\n",
        "    packing=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCCwez1-ZFoX"
      },
      "source": [
        "* https://huggingface.co/docs/trl/en/sft_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RZNQhfj6APJn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "f3c54ae115c04748b7ca785b731d8e80",
            "39974f8251f9460cbf58437dfae486b4",
            "a0e47172b9ef46188da3c114f98f6777",
            "ec959ad37df54654a82d7c987792ed21",
            "f0467853243046df940134f2f732cc64",
            "55e42701ff5241c4b68b0bcc6b492505",
            "ad55299290b44f6fa0f2a232893d167b",
            "2b341025104045419c6b34b2635f2c03",
            "52c117822906452b9063b3db4e1ebcaf",
            "88dae8febc6541239010ab55eb9a57cf",
            "371f2f41a5d844dba3f4d8b6f9f13917",
            "69f2a1a1441f43b2acb14dce874b6066",
            "a3b04cd90c2d4711becc1fa26392f2d7",
            "ac047234bbcd458f8e2344d99615c297",
            "61068c68bd1c43e890b34d828bec9cf4",
            "7eeeeda2ec6e4e18b69760d0117e9d96",
            "1a0e7ee082d24522815170ca9880e4f8",
            "4e36811043994c159ca8a91eb9a34758",
            "36081ba47ca94e5bb4bc6dfb7a60f258",
            "6825a708033c4b5196903782a5d2a901",
            "84aa8e409c884b2bb5a694e42327340d",
            "bdb502e12cb249f09152aa29ce2e196b"
          ]
        },
        "outputId": "c47a9d2c-4264-40bf-ad76-da4328cf96e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/utils.py:616: UserWarning: The passed formatting_func has more than one argument. Usually that function should have a single argument `example` which corresponds to the dictionary returned by each element of the dataset. Make sure you know what you are doing.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3c54ae115c04748b7ca785b731d8e80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69f2a1a1441f43b2acb14dce874b6066"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:421: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = trl.SFTTrainer(\n",
        "    model=model,\n",
        "    peft_config=peft_config,\n",
        "    tokenizer=tokenizer,\n",
        "    formatting_func=create_prompt,\n",
        "    args=args,\n",
        "    train_dataset=legal_dataset[\"train\"],\n",
        "    eval_dataset=legal_dataset[\"validation\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "wVBOIpVJguii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYYoxEoEOPDY"
      },
      "source": [
        "## Task #5: Share Your Model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkD5hMhLMSzZ"
      },
      "outputs": [],
      "source": [
        "huggingface_hub.notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UOvMTDXMX28"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(\"SethWeidman/llama381binstruct_summarize_short_merged_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAudsV-O4nT"
      },
      "source": [
        "### Compare Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKXqRmOLMdYD"
      },
      "outputs": [],
      "source": [
        "merged_model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6ulAvzY4tFG"
      },
      "outputs": [],
      "source": [
        "merged_model.push_to_hub(\n",
        "    \"SethWeidman/llama381binstruct_summarize_short_merged_test\",\n",
        "    safe_serialization=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwGvR26s-ExZ"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(\"SethWeidman/llama381binstruct_summarize_short_merged_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mikYCAawMf7p"
      },
      "outputs": [],
      "source": [
        "generate_response(\n",
        "    create_prompt(legal_dataset[\"test\"][1], include_response=False),\n",
        "    merged_model,\n",
        "    tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIyf0Cie6BwA"
      },
      "outputs": [],
      "source": [
        "legal_dataset[\"test\"][3][\"original_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQuDEmNGdCFi"
      },
      "outputs": [],
      "source": [
        "generate_response(\n",
        "    create_prompt(legal_dataset[\"test\"][3], include_response=False),\n",
        "    merged_model,\n",
        "    tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO4uEcuHfhWH"
      },
      "outputs": [],
      "source": [
        "# Ground Truth Summary\n",
        "legal_dataset[\"test\"][3][\"reference_summary\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3c54ae115c04748b7ca785b731d8e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39974f8251f9460cbf58437dfae486b4",
              "IPY_MODEL_a0e47172b9ef46188da3c114f98f6777",
              "IPY_MODEL_ec959ad37df54654a82d7c987792ed21"
            ],
            "layout": "IPY_MODEL_f0467853243046df940134f2f732cc64"
          }
        },
        "39974f8251f9460cbf58437dfae486b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e42701ff5241c4b68b0bcc6b492505",
            "placeholder": "​",
            "style": "IPY_MODEL_ad55299290b44f6fa0f2a232893d167b",
            "value": "Generating train split: "
          }
        },
        "a0e47172b9ef46188da3c114f98f6777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b341025104045419c6b34b2635f2c03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c117822906452b9063b3db4e1ebcaf",
            "value": 1
          }
        },
        "ec959ad37df54654a82d7c987792ed21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dae8febc6541239010ab55eb9a57cf",
            "placeholder": "​",
            "style": "IPY_MODEL_371f2f41a5d844dba3f4d8b6f9f13917",
            "value": " 9/0 [00:00&lt;00:00, 194.68 examples/s]"
          }
        },
        "f0467853243046df940134f2f732cc64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e42701ff5241c4b68b0bcc6b492505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad55299290b44f6fa0f2a232893d167b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b341025104045419c6b34b2635f2c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52c117822906452b9063b3db4e1ebcaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88dae8febc6541239010ab55eb9a57cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "371f2f41a5d844dba3f4d8b6f9f13917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f2a1a1441f43b2acb14dce874b6066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3b04cd90c2d4711becc1fa26392f2d7",
              "IPY_MODEL_ac047234bbcd458f8e2344d99615c297",
              "IPY_MODEL_61068c68bd1c43e890b34d828bec9cf4"
            ],
            "layout": "IPY_MODEL_7eeeeda2ec6e4e18b69760d0117e9d96"
          }
        },
        "a3b04cd90c2d4711becc1fa26392f2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a0e7ee082d24522815170ca9880e4f8",
            "placeholder": "​",
            "style": "IPY_MODEL_4e36811043994c159ca8a91eb9a34758",
            "value": "Generating train split: "
          }
        },
        "ac047234bbcd458f8e2344d99615c297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36081ba47ca94e5bb4bc6dfb7a60f258",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6825a708033c4b5196903782a5d2a901",
            "value": 1
          }
        },
        "61068c68bd1c43e890b34d828bec9cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84aa8e409c884b2bb5a694e42327340d",
            "placeholder": "​",
            "style": "IPY_MODEL_bdb502e12cb249f09152aa29ce2e196b",
            "value": " 1/0 [00:00&lt;00:00, 41.17 examples/s]"
          }
        },
        "7eeeeda2ec6e4e18b69760d0117e9d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0e7ee082d24522815170ca9880e4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e36811043994c159ca8a91eb9a34758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36081ba47ca94e5bb4bc6dfb7a60f258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6825a708033c4b5196903782a5d2a901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84aa8e409c884b2bb5a694e42327340d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb502e12cb249f09152aa29ce2e196b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}